{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello teacher\n"
     ]
    }
   ],
   "source": [
    "'''Инструкция к сдаче\n",
    "Настоятельно рекомендуем сдавать практическое задание в виде ссылки на личный репозиторий на github.\n",
    "Рекомендуемый способ организации данных в репозитории: создать отдельные папки по темам и помещать в них отдельные файлы для каждой задачи с правильным расширением.\n",
    "\n",
    "Ссылка на инструкцию по работе с git и сдачу практики:\n",
    "https://docs.google.com/document/d/1RAT_ukE39iOfbz1xa39QXae2hBUEZ4U6Fko_wFDdrsM/edit\n",
    "Ссылка на видеокурс по Git:\n",
    "https://geekbrains.ru/courses/66\n",
    "Если остались сложности с системой git, то обратитесь к преподавателю или наставнику.\n",
    "\n",
    "Тема “Вычисления с помощью Numpy”\n",
    "Задание 1\n",
    "Импортируйте библиотеку Numpy и дайте ей псевдоним np.\n",
    "Создайте массив Numpy под названием a размером 5x2, то есть состоящий из 5 строк и 2 столбцов. Первый столбец должен содержать числа 1, 2, 3, 3, 1, а второй - числа 6, 8, 11, 10, 7. Будем считать, что каждый столбец - это признак, а строка - наблюдение. Затем найдите среднее значение по каждому признаку, используя метод mean массива Numpy. Результат запишите в массив mean_a, в нем должно быть 2 элемента.\n",
    "Задание 2\n",
    "Вычислите массив a_centered, отняв от значений массива “а” средние значения соответствующих признаков, содержащиеся в массиве mean_a. Вычисление должно производиться в одно действие. Получившийся массив должен иметь размер 5x2.\n",
    "Задание 3\n",
    "Найдите скалярное произведение столбцов массива a_centered. В результате должна получиться величина a_centered_sp. Затем поделите a_centered_sp на N-1, где N - число наблюдений.\n",
    "Задание 4**\n",
    "Число, которое мы получили в конце задания 3 является ковариацией двух признаков, содержащихся в массиве “а”. В задании 4 мы делили сумму произведений центрированных признаков на N-1, а не на N, поэтому полученная нами величина является несмещенной оценкой ковариации.\n",
    "Подробнее узнать о ковариации можно здесь:\n",
    "https://studopedia.ru/9_153900_viborochnaya-kovariatsiya-i-viborochnaya-dispersiya.html\n",
    "В этом задании проверьте получившееся число, вычислив ковариацию еще одним способом - с помощью функции np.cov. В качестве аргумента m функция np.cov должна принимать транспонированный массив “a”. В получившейся ковариационной матрице (массив Numpy размером 2x2) искомое значение ковариации будет равно элементу в строке с индексом 0 и столбце с индексом 1.\n",
    "\n",
    "Тема “Работа с данными в Pandas”\n",
    "Задание 1\n",
    "Импортируйте библиотеку Pandas и дайте ей псевдоним pd. Создайте датафрейм authors со столбцами author_id и author_name, в которых соответственно содержатся данные: [1, 2, 3] и ['Тургенев', 'Чехов', 'Островский'].\n",
    "Затем создайте датафрейм book cо столбцами author_id, book_title и price, в которых соответственно содержатся данные: \n",
    "[1, 1, 1, 2, 2, 3, 3], \n",
    "['Отцы и дети', 'Рудин', 'Дворянское гнездо', 'Толстый и тонкий', 'Дама с собачкой', 'Гроза', 'Таланты и поклонники'],\n",
    "[450, 300, 350, 500, 450, 370, 290].\n",
    "Задание 2\n",
    "Получите датафрейм authors_price, соединив датафреймы authors и books по полю author_id.\n",
    "Задание 3\n",
    "Создайте датафрейм top5, в котором содержатся строки из authors_price с пятью самыми дорогими книгами.\n",
    "Задание 4\n",
    "Создайте датафрейм authors_stat на основе информации из authors_price. В датафрейме authors_stat должны быть четыре столбца:\n",
    "author_name, min_price, max_price и mean_price,\n",
    "в которых должны содержаться соответственно имя автора,минимальная, максимальная и средняя цена на книги этого автора.\n",
    "Задание 5**\n",
    "Создайте новый столбец в датафрейме authors_price под названием cover, в нем будут располагаться данные о том, какая обложка у данной книги - твердая или мягкая. В этот столбец поместите данные из следующего списка:\n",
    "['твердая', 'мягкая', 'мягкая', 'твердая', 'твердая', 'мягкая', 'мягкая'].\n",
    "Просмотрите документацию по функции pd.pivot_table с помощью вопросительного знака.Для каждого автора посчитайте суммарную стоимость книг в твердой и мягкой обложке. Используйте для этого функцию pd.pivot_table. При этом столбцы должны называться \"твердая\" и \"мягкая\", а индексами должны быть фамилии авторов. Пропущенные значения стоимостей заполните нулями, при необходимости загрузите библиотеку Numpy.\n",
    "Назовите полученный датасет book_info и сохраните его в формат pickle под названием \"book_info.pkl\". Затем загрузите из этого файла датафрейм и назовите его book_info2. Удостоверьтесь, что датафреймы book_info и book_info2 идентичны.\n",
    "\n",
    "'''\n",
    "print('Hello teacher')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 1\n",
    "'''Импортируйте библиотеку Numpy и дайте ей псевдоним np.\n",
    "Создайте массив Numpy под названием a размером 5x2, то \n",
    "есть состоящий из 5 строк и 2 столбцов. Первый столбец\n",
    "должен содержать числа 1, 2, 3, 3, 1, а второй - числа\n",
    "6, 8, 11, 10, 7. Будем считать, что каждый столбец - это\n",
    "признак, а строка - наблюдение. Затем найдите среднее значение\n",
    "по каждому признаку, используя метод mean массива Numpy.\n",
    "Результат запишите в массив mean_a, в нем должно быть 2 элемента.\n",
    "'''\n",
    "a = np.array([[1, 2, 3, 3, 1],[6, 8, 11, 10, 7]])\n",
    "a = a.transpose(None)\n",
    "mean_a=a.mean(axis=0)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 2\n",
    "'''Вычислите массив a_centered, отняв от значений массива “а” \n",
    "средние значения соответствующих признаков, содержащиеся в \n",
    "массиве mean_a. Вычисление должно производиться в одно действие.\n",
    "Получившийся массив должен иметь размер 5x2.'''\n",
    "a_centered=np.subtract(a, mean_a)\n",
    "a_centered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 3\n",
    "'''Найдите скалярное произведение столбцов массива a_centered. В результате должна получиться \n",
    "величина a_centered_sp. Затем поделите a_centered_sp на N-1, где N - число наблюдений.'''\n",
    "a_centered_sp = np.dot(a_centered[:,0], a_centered[:,1])\n",
    "a_centered_sp\n",
    "a_cov = a_centered_sp/4\n",
    "a_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 2. ],\n",
       "       [2. , 4.3]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 4\n",
    "'''Число, которое мы получили в конце задания 3 является ковариацией двух\n",
    "признаков, содержащихся в массиве “а”. В задании 4 мы делили сумму произведений\n",
    "центрированных признаков на N-1, а не на N, поэтому полученная нами величина\n",
    "является несмещенной оценкой ковариации.\n",
    "Подробнее узнать о ковариации можно здесь:\n",
    "https://studopedia.ru/9_153900_viborochnaya-kovariatsiya-i-viborochnaya-dispersiya.html\n",
    "В этом задании проверьте получившееся число, вычислив ковариацию еще одним способом\n",
    "- с помощью функции np.cov. В качестве аргумента m функция np.cov должна принимать\n",
    "транспонированный массив “a”. В получившейся ковариационной матрице (массив Numpy размером 2x2)\n",
    "искомое значение ковариации будет равно элементу в строке с индексом 0 и столбце с индексом 1.\n",
    "'''\n",
    "\n",
    "a_transpose = a.transpose(None)\n",
    "a_transpose\n",
    "a_cov_method_2 = np.cov(a_transpose)\n",
    "print(a_cov_method_2)\n",
    "print (a_cov_method_2[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1\n",
    "'''Импортируйте библиотеку Pandas и дайте ей псевдоним pd. Создайте датафрейм authors со столбцами author_id и author_name, \n",
    "в которых соответственно содержатся данные: [1, 2, 3] и ['Тургенев', 'Чехов', 'Островский'].\n",
    "Затем создайте датафрейм book cо столбцами author_id, book_title и price, в которых соответственно содержатся данные: \n",
    "[1, 1, 1, 2, 2, 3, 3], \n",
    "['Отцы и дети', 'Рудин', 'Дворянское гнездо', 'Толстый и тонкий', 'Дама с собачкой', 'Гроза', 'Таланты и поклонники'],\n",
    "[450, 300, 350, 500, 450, 370, 290].\n",
    "'''\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_id = [1,2,3]\n",
    "author_name = ['Тургенев', 'Чехов', 'Островский']\n",
    "book_author_id = [1, 1, 1, 2, 2, 3, 3]\n",
    "book_title = ['Отцы и дети', 'Рудин', 'Дворянское гнездо', 'Толстый и тонкий', 'Дама с собачкой', 'Гроза', 'Таланты и поклонники']\n",
    "price =[450, 300, 350, 500, 450, 370, 290]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Author_id author_name\n",
      "0          1    Тургенев\n",
      "1          2       Чехов\n",
      "2          3  Островский\n"
     ]
    }
   ],
   "source": [
    "authors = pd.DataFrame(\n",
    "    {'Author_id': authors_id,\n",
    "    'author_name': author_name}\n",
    "                      )\n",
    "print(authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Author_id            Book Title  Price\n",
      "0          1           Отцы и дети    450\n",
      "1          1                 Рудин    300\n",
      "2          1     Дворянское гнездо    350\n",
      "3          2      Толстый и тонкий    500\n",
      "4          2       Дама с собачкой    450\n",
      "5          3                 Гроза    370\n",
      "6          3  Таланты и поклонники    290\n"
     ]
    }
   ],
   "source": [
    "books = pd.DataFrame(\n",
    "    {'Author_id': book_author_id,\n",
    "     'Book Title': book_title,\n",
    "    'Price': price}\n",
    "                      )\n",
    "print(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Author_id author_name            Book Title  Price\n",
      "0          1    Тургенев           Отцы и дети    450\n",
      "1          1    Тургенев                 Рудин    300\n",
      "2          1    Тургенев     Дворянское гнездо    350\n",
      "3          2       Чехов      Толстый и тонкий    500\n",
      "4          2       Чехов       Дама с собачкой    450\n",
      "5          3  Островский                 Гроза    370\n",
      "6          3  Островский  Таланты и поклонники    290\n"
     ]
    }
   ],
   "source": [
    "# Task 2\n",
    "'''Получите датафрейм authors_price, соединив датафреймы authors и books по полю author_id.'''\n",
    "authors_price  =  pd.merge(authors, books, on='Author_id', how='left')\n",
    "print(authors_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author_id</th>\n",
       "      <th>author_name</th>\n",
       "      <th>Book Title</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Чехов</td>\n",
       "      <td>Толстый и тонкий</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Тургенев</td>\n",
       "      <td>Отцы и дети</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Чехов</td>\n",
       "      <td>Дама с собачкой</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Островский</td>\n",
       "      <td>Гроза</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Тургенев</td>\n",
       "      <td>Дворянское гнездо</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Author_id author_name         Book Title  Price\n",
       "3          2       Чехов   Толстый и тонкий    500\n",
       "0          1    Тургенев        Отцы и дети    450\n",
       "4          2       Чехов    Дама с собачкой    450\n",
       "5          3  Островский              Гроза    370\n",
       "2          1    Тургенев  Дворянское гнездо    350"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 3\n",
    "'''Создайте датафрейм top5, в котором содержатся строки из authors_price с пятью самыми дорогими книгами.'''\n",
    "top_5 = authors_price.nlargest(5, 'Price')\n",
    "top_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Price</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Островский</td>\n",
       "      <td>290</td>\n",
       "      <td>370</td>\n",
       "      <td>330.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Тургенев</td>\n",
       "      <td>300</td>\n",
       "      <td>450</td>\n",
       "      <td>366.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Чехов</td>\n",
       "      <td>450</td>\n",
       "      <td>500</td>\n",
       "      <td>475.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Price  Price       Price\n",
       "author_name                          \n",
       "Островский     290    370  330.000000\n",
       "Тургенев       300    450  366.666667\n",
       "Чехов          450    500  475.000000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 4\n",
    "'''Создайте датафрейм authors_stat на основе информации из authors_price. В датафрейме authors_stat должны быть четыре столбца:\n",
    "author_name, min_price, max_price и mean_price,\n",
    "в которых должны содержаться соответственно имя автора,минимальная, максимальная и средняя цена на книги этого автора.\n",
    "'''\n",
    "df1 = authors_price.groupby('author_name').agg({'Price': 'min'}).rename(columns={'price':'min_price'})\n",
    "df2 = authors_price.groupby('author_name').agg({'Price': 'max'}).rename(columns={'price':'max_price'})\n",
    "df3 = authors_price.groupby('author_name').agg({'Price': 'mean'}).rename(columns={'price':'mean_price'})\n",
    "authors_stat=pd.concat([df1, df2, df3], axis = 1)\n",
    "authors_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpivot_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0maggfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mean'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmargins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdropna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmargins_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'All'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mobserved\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Create a spreadsheet-style pivot table as a DataFrame. The levels in\n",
       "the pivot table will be stored in MultiIndex objects (hierarchical\n",
       "indexes) on the index and columns of the result DataFrame.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "data : DataFrame\n",
       "values : column to aggregate, optional\n",
       "index : column, Grouper, array, or list of the previous\n",
       "    If an array is passed, it must be the same length as the data. The\n",
       "    list can contain any of the other types (except list).\n",
       "    Keys to group by on the pivot table index.  If an array is passed,\n",
       "    it is being used as the same manner as column values.\n",
       "columns : column, Grouper, array, or list of the previous\n",
       "    If an array is passed, it must be the same length as the data. The\n",
       "    list can contain any of the other types (except list).\n",
       "    Keys to group by on the pivot table column.  If an array is passed,\n",
       "    it is being used as the same manner as column values.\n",
       "aggfunc : function, list of functions, dict, default numpy.mean\n",
       "    If list of functions passed, the resulting pivot table will have\n",
       "    hierarchical columns whose top level are the function names\n",
       "    (inferred from the function objects themselves)\n",
       "    If dict is passed, the key is column to aggregate and value\n",
       "    is function or list of functions\n",
       "fill_value : scalar, default None\n",
       "    Value to replace missing values with\n",
       "margins : boolean, default False\n",
       "    Add all row / columns (e.g. for subtotal / grand totals)\n",
       "dropna : boolean, default True\n",
       "    Do not include columns whose entries are all NaN\n",
       "margins_name : string, default 'All'\n",
       "    Name of the row / column that will contain the totals\n",
       "    when margins is True.\n",
       "observed : boolean, default False\n",
       "    This only applies if any of the groupers are Categoricals.\n",
       "    If True: only show observed values for categorical groupers.\n",
       "    If False: show all values for categorical groupers.\n",
       "\n",
       "    .. versionchanged :: 0.25.0\n",
       "\n",
       "Returns\n",
       "-------\n",
       "DataFrame\n",
       "\n",
       "See Also\n",
       "--------\n",
       "DataFrame.pivot : Pivot without aggregation that can handle\n",
       "    non-numeric data.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> df = pd.DataFrame({\"A\": [\"foo\", \"foo\", \"foo\", \"foo\", \"foo\",\n",
       "...                          \"bar\", \"bar\", \"bar\", \"bar\"],\n",
       "...                    \"B\": [\"one\", \"one\", \"one\", \"two\", \"two\",\n",
       "...                          \"one\", \"one\", \"two\", \"two\"],\n",
       "...                    \"C\": [\"small\", \"large\", \"large\", \"small\",\n",
       "...                          \"small\", \"large\", \"small\", \"small\",\n",
       "...                          \"large\"],\n",
       "...                    \"D\": [1, 2, 2, 3, 3, 4, 5, 6, 7],\n",
       "...                    \"E\": [2, 4, 5, 5, 6, 6, 8, 9, 9]})\n",
       ">>> df\n",
       "     A    B      C  D  E\n",
       "0  foo  one  small  1  2\n",
       "1  foo  one  large  2  4\n",
       "2  foo  one  large  2  5\n",
       "3  foo  two  small  3  5\n",
       "4  foo  two  small  3  6\n",
       "5  bar  one  large  4  6\n",
       "6  bar  one  small  5  8\n",
       "7  bar  two  small  6  9\n",
       "8  bar  two  large  7  9\n",
       "\n",
       "This first example aggregates values by taking the sum.\n",
       "\n",
       ">>> table = pd.pivot_table(df, values='D', index=['A', 'B'],\n",
       "...                     columns=['C'], aggfunc=np.sum)\n",
       ">>> table\n",
       "C        large  small\n",
       "A   B\n",
       "bar one    4.0    5.0\n",
       "    two    7.0    6.0\n",
       "foo one    4.0    1.0\n",
       "    two    NaN    6.0\n",
       "\n",
       "We can also fill missing values using the `fill_value` parameter.\n",
       "\n",
       ">>> table = pd.pivot_table(df, values='D', index=['A', 'B'],\n",
       "...                     columns=['C'], aggfunc=np.sum, fill_value=0)\n",
       ">>> table\n",
       "C        large  small\n",
       "A   B\n",
       "bar one      4      5\n",
       "    two      7      6\n",
       "foo one      4      1\n",
       "    two      0      6\n",
       "\n",
       "The next example aggregates by taking the mean across multiple columns.\n",
       "\n",
       ">>> table = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n",
       "...                     aggfunc={'D': np.mean,\n",
       "...                              'E': np.mean})\n",
       ">>> table\n",
       "                D         E\n",
       "A   C\n",
       "bar large  5.500000  7.500000\n",
       "    small  5.500000  8.500000\n",
       "foo large  2.000000  4.500000\n",
       "    small  2.333333  4.333333\n",
       "\n",
       "We can also calculate multiple types of aggregations for any given\n",
       "value column.\n",
       "\n",
       ">>> table = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n",
       "...                     aggfunc={'D': np.mean,\n",
       "...                              'E': [min, max, np.mean]})\n",
       ">>> table\n",
       "                D    E\n",
       "            mean  max      mean  min\n",
       "A   C\n",
       "bar large  5.500000  9.0  7.500000  6.0\n",
       "    small  5.500000  9.0  8.500000  8.0\n",
       "foo large  2.000000  5.0  4.500000  4.0\n",
       "    small  2.333333  6.0  4.333333  2.0\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\programdata\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\pivot.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''Задание 5**\n",
    "Создайте новый столбец в датафрейме authors_price под названием cover,\n",
    "в нем будут располагаться данные о том, какая обложка у данной книги\n",
    "- твердая или мягкая. В этот столбец поместите данные из следующего списка:\n",
    "['твердая', 'мягкая', 'мягкая', 'твердая', 'твердая', 'мягкая', 'мягкая'].'''\n",
    "\n",
    "df1 = pd.DataFrame({'cover':['твердая', 'мягкая', 'мягкая', 'твердая', 'твердая', 'мягкая', 'мягкая']}, columns=['cover'])\n",
    "authors_price = pd.concat([authors_price, df1], axis = 1)\n",
    "authors_price\n",
    "\n",
    "'''Просмотрите документацию по функции pd.pivot_table с помощью вопросительного\n",
    "знака.'''\n",
    "?pd.pivot_table\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Grouper for 'cover' not 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-4533a22d8751>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m Пропущенные значения стоимостей заполните нулями, при необходимости загрузите библиотеку Numpy.'''\n\u001b[0;32m      5\u001b[0m book_info = pd.pivot_table(authors_price, values='Price', index=['author_name'],\n\u001b[1;32m----> 6\u001b[1;33m                     columns=['cover'], aggfunc=np.sum, fill_value=0)\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mbook_info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\pivot.py\u001b[0m in \u001b[0;36mpivot_table\u001b[1;34m(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed)\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m     \u001b[0mgrouped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobserved\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobserved\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m     \u001b[0magged\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrouped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maggfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdropna\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magged\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCDataFrame\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magged\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, **kwargs)\u001b[0m\n\u001b[0;32m   7892\u001b[0m             \u001b[0msqueeze\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7893\u001b[0m             \u001b[0mobserved\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobserved\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7894\u001b[1;33m             \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7895\u001b[0m         )\n\u001b[0;32m   7896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(obj, by, **kwds)\u001b[0m\n\u001b[0;32m   2520\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"invalid type: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2522\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, **kwargs)\u001b[0m\n\u001b[0;32m    389\u001b[0m                 \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m                 \u001b[0mobserved\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobserved\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 391\u001b[1;33m                 \u001b[0mmutated\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmutated\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    392\u001b[0m             )\n\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py\u001b[0m in \u001b[0;36m_get_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, mutated, validate)\u001b[0m\n\u001b[0;32m    650\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0min_axis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m             )\n\u001b[1;32m--> 652\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGrouping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    653\u001b[0m             \u001b[1;32melse\u001b[0m \u001b[0mgpr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m         )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, index, grouper, obj, name, level, sort, observed, in_axis)\u001b[0m\n\u001b[0;32m    345\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ndim\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m                     \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 347\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Grouper for '{}' not 1-dimensional\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    348\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrouper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m                 if not (\n",
      "\u001b[1;31mValueError\u001b[0m: Grouper for 'cover' not 1-dimensional"
     ]
    }
   ],
   "source": [
    "'''Для каждого автора посчитайте суммарную стоимость книг в твердой и мягкой \n",
    "обложке. Используйте для этого функцию pd.pivot_table. При этом столбцы должны \n",
    "называться \"твердая\" и \"мягкая\", а индексами должны быть фамилии авторов. \n",
    "Пропущенные значения стоимостей заполните нулями, при необходимости загрузите библиотеку Numpy.'''\n",
    "book_info = pd.pivot_table(authors_price, values='Price', index=['author_name'],\n",
    "                    columns=['cover'], aggfunc=np.sum, fill_value=0)\n",
    "book_info\n",
    "\n",
    "'''Назовите полученный датасет book_info и сохраните его в формат pickle под названием\n",
    "\"book_info.pkl\". '''\n",
    "\n",
    "book_info.to_pickle('book_info.pkl')\n",
    "\n",
    "'''Затем загрузите из этого файла датафрейм и назовите его book_info2.'''\n",
    "\n",
    "book_info2 = pd.read_pickle('book_info.pkl')\n",
    "\n",
    "'''Удостоверьтесь, что датафреймы book_info и book_info2 идентичны.'''\n",
    "\n",
    "\n",
    "\n",
    "book_info==book_info2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
